{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyNrcqj4vNW0ovVwaLJm9W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pytee/geminiintro/blob/main/imageprocessinggemini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yY7DvrrDMV2O"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "import google.generativeai as genai\n",
        "from IPython.display import Markdown\n",
        "import PIL.Image\n",
        "import urllib.request"
      ],
      "metadata": {
        "id": "o5Q0hc6sMgqZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
        "GOOGLE_API_KEY=userdata.get(\"GEMINI_API_KEY\")\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "irdYZff4MiSs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "    if \"generateContent\" in m.supported_generation_methods:\n",
        "        print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "vbSQ8KgeMlaC",
        "outputId": "c34c13ef-0f64-4531-af75-f3e4c4ddc607"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "for model in genai.list_models():\n",
        "    pprint.pprint(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PuZpJqv1Mpz_",
        "outputId": "dc378db2-a76e-4db3-eb41-447cd5ebc341"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(name='models/chat-bison-001',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='PaLM 2 Chat (Legacy)',\n",
            "      description='A legacy text-only model optimized for chat conversations',\n",
            "      input_token_limit=4096,\n",
            "      output_token_limit=1024,\n",
            "      supported_generation_methods=['generateMessage', 'countMessageTokens'],\n",
            "      temperature=0.25,\n",
            "      top_p=0.95,\n",
            "      top_k=40)\n",
            "Model(name='models/text-bison-001',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='PaLM 2 (Legacy)',\n",
            "      description='A legacy model that understands text and generates text as an output',\n",
            "      input_token_limit=8196,\n",
            "      output_token_limit=1024,\n",
            "      supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n",
            "      temperature=0.7,\n",
            "      top_p=0.95,\n",
            "      top_k=40)\n",
            "Model(name='models/embedding-gecko-001',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Embedding Gecko',\n",
            "      description='Obtain a distributed representation of a text.',\n",
            "      input_token_limit=1024,\n",
            "      output_token_limit=1,\n",
            "      supported_generation_methods=['embedText', 'countTextTokens'],\n",
            "      temperature=None,\n",
            "      top_p=None,\n",
            "      top_k=None)\n",
            "Model(name='models/gemini-pro',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini Pro',\n",
            "      description='The best model for scaling across a wide range of tasks',\n",
            "      input_token_limit=30720,\n",
            "      output_token_limit=2048,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=0.9,\n",
            "      top_p=1.0,\n",
            "      top_k=1)\n",
            "Model(name='models/gemini-pro-vision',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini Pro Vision',\n",
            "      description='The best image understanding model to handle a broad range of applications',\n",
            "      input_token_limit=12288,\n",
            "      output_token_limit=4096,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=0.4,\n",
            "      top_p=1.0,\n",
            "      top_k=32)\n",
            "Model(name='models/embedding-001',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Embedding 001',\n",
            "      description='Obtain a distributed representation of a text.',\n",
            "      input_token_limit=2048,\n",
            "      output_token_limit=1,\n",
            "      supported_generation_methods=['embedContent', 'countTextTokens'],\n",
            "      temperature=None,\n",
            "      top_p=None,\n",
            "      top_k=None)\n",
            "Model(name='models/aqa',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Model that performs Attributed Question Answering.',\n",
            "      description=('Model trained to return answers to questions that are grounded in provided '\n",
            "                   'sources, along with estimating answerable probability.'),\n",
            "      input_token_limit=7168,\n",
            "      output_token_limit=1024,\n",
            "      supported_generation_methods=['generateAnswer'],\n",
            "      temperature=0.2,\n",
            "      top_p=1.0,\n",
            "      top_k=40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def to_markdown(text):\n",
        "    text = text.replace(\"â€¢\", \"  *\")\n",
        "    return Markdown(textwrap.indent(text, \"> \", predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "XCpT0X_XMraa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(\"gemini-pro\")"
      ],
      "metadata": {
        "id": "mitLvUqpMn0f"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"Write a code for different image processing techniques in Python programming language, I would be running the code in Google colab\",\n",
        "    stream=True\n",
        ")\n",
        "\n",
        "response.resolve()\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "id": "U1HVrzRONo3D",
        "outputId": "ab32cfd0-11ad-4754-ffaf-5855c237aee7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> 1. **Import necessary libraries**: \n> ```\n> import cv2\n> import numpy as np\n> from PIL import Image\n> ```\n> 2. **Load an image**:\n> ```\n> image = cv2.imread('image.jpg')\n> ```\n> 3. **Convert the image to grayscale**:\n> ```\n> gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n> ```\n> 4. **Blur the image**:\n> ```\n> blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n> ```\n> 5. **Sharpen the image**:\n> ```\n> sharpened_image = cv2.Laplacian(gray_image, cv2.CV_64F)\n> ```\n> 6. **Detect edges in the image**:\n> ```\n> edges_image = cv2.Canny(gray_image, 100, 200)\n> ```\n> 7. **Dilate the edges**:\n> ```\n> dilated_edges = cv2.dilate(edges_image, np.ones((5, 5), np.uint8), iterations = 1)\n> ```\n> 8. **Erode the edges**:\n> ```\n> eroded_edges = cv2.erode(edges_image, np.ones((5, 5), np.uint8), iterations = 1)\n> ```\n> 9. **Resize the image**:\n> ```\n> resized_image = cv2.resize(image, (200, 200))\n> ```\n> 10. **Rotate the image**:\n> ```\n> rotated_image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n> ```\n> 11. **Flip the image**:\n> ```\n> flipped_image = cv2.flip(image, 1)\n> ```\n> 12. **Adjust the brightness and contrast of the image**:\n> ```\n> bright_image = cv2.addWeighted(image, 1.5, np.zeros(image.shape, image.dtype), 0, 0)\n> contrasted_image = cv2.addWeighted(image, 1.5, np.zeros(image.shape, image.dtype), 0, -50)\n> ```\n> 13. **Save the image to a file**:\n> ```\n> cv2.imwrite('processed_image.jpg', processed_image)\n> ```\n> 14. **Display the image**:\n> ```\n> cv2.imshow('Image', image)\n> cv2.waitKey(0)\n> cv2.destroyAllWindows()\n> ```\n> \n> **Additional Notes**:\n> \n> 1. You can find more image processing techniques by exploring the OpenCV documentation.\n> \n> 2. If you are using Google Colab, you can upload your image to the Colab notebook by clicking on the \"Files\" tab and then \"Upload\". You can then load the image using the `cv2.imread()` function.\n> \n> 3. You can also use Python's `PIL` library for image processing. The `Image` class in `PIL` provides a number of methods for manipulating images.\n> \n> 4. Be sure to save the processed image to a file or display it on the screen before exiting the program."
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}